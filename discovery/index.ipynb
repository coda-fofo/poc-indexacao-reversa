{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f29c0528",
   "metadata": {},
   "source": [
    "### Primeiro, bora ler um arquivo de exemplo com informações base dos tatuadores."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "2eaf41d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome_de_usuario</th>\n",
       "      <th>nome_completo</th>\n",
       "      <th>descricao</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>caio_porcel</td>\n",
       "      <td>Caio Henrique Porcel</td>\n",
       "      <td>Sou um tatuador especializado em Old School</td>\n",
       "      <td>oldschool,curitiba,brasil,sao-paulo,retro</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kauan_alexandre</td>\n",
       "      <td>Kauan Alexandre Mendes da Silva</td>\n",
       "      <td>Realismo mágico | SP</td>\n",
       "      <td>realismo,sao-paulo,sp,rutz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>joao_pedro</td>\n",
       "      <td>João Pedro de Oliveira</td>\n",
       "      <td>O tatuador mais fofo de fineline de Porto Alegre</td>\n",
       "      <td>fineline,fofura,porto-alegre</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>vinicius_rebelatto</td>\n",
       "      <td>Vinicius Rebelatto</td>\n",
       "      <td>Leões e relógios, praia e vôlei</td>\n",
       "      <td>leão,relógio,praia,volei,curitiba</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>lara_ink</td>\n",
       "      <td>Lara Cristina Souza</td>\n",
       "      <td>Tatuagens delicadas e florais com alma feminina</td>\n",
       "      <td>delicada,floral,sp,sao-paulo,feminina</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      nome_de_usuario                    nome_completo  \\\n",
       "0         caio_porcel             Caio Henrique Porcel   \n",
       "1     kauan_alexandre  Kauan Alexandre Mendes da Silva   \n",
       "2          joao_pedro           João Pedro de Oliveira   \n",
       "3  vinicius_rebelatto               Vinicius Rebelatto   \n",
       "4            lara_ink              Lara Cristina Souza   \n",
       "\n",
       "                                          descricao  \\\n",
       "0       Sou um tatuador especializado em Old School   \n",
       "1                              Realismo mágico | SP   \n",
       "2  O tatuador mais fofo de fineline de Porto Alegre   \n",
       "3                   Leões e relógios, praia e vôlei   \n",
       "4   Tatuagens delicadas e florais com alma feminina   \n",
       "\n",
       "                                    hashtags  \n",
       "0  oldschool,curitiba,brasil,sao-paulo,retro  \n",
       "1                 realismo,sao-paulo,sp,rutz  \n",
       "2               fineline,fofura,porto-alegre  \n",
       "3          leão,relógio,praia,volei,curitiba  \n",
       "4      delicada,floral,sp,sao-paulo,feminina  "
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv('./assets/tatuadores.csv', sep=';')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8234782f",
   "metadata": {},
   "source": [
    "### Depois, vamos testar o NLTK para tokenizar as palavras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "50124df0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/thundera/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome_completo</th>\n",
       "      <th>descricao</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[Caio, Henrique, Porcel]</td>\n",
       "      <td>[Sou, um, tatuador, especializado, em, Old, Sc...</td>\n",
       "      <td>[oldschool, curitiba, brasil, sao-paulo, retro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[Kauan, Alexandre, Mendes, da, Silva]</td>\n",
       "      <td>[Realismo, mágico, |, SP]</td>\n",
       "      <td>[realismo, sao-paulo, sp, rutz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[João, Pedro, de, Oliveira]</td>\n",
       "      <td>[O, tatuador, mais, fofo, de, fineline, de, Po...</td>\n",
       "      <td>[fineline, fofura, porto-alegre]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[Vinicius, Rebelatto]</td>\n",
       "      <td>[Leões, e, relógios, ,, praia, e, vôlei]</td>\n",
       "      <td>[leão, relógio, praia, volei, curitiba]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[Lara, Cristina, Souza]</td>\n",
       "      <td>[Tatuagens, delicadas, e, florais, com, alma, ...</td>\n",
       "      <td>[delicada, floral, sp, sao-paulo, feminina]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           nome_completo  \\\n",
       "0               [Caio, Henrique, Porcel]   \n",
       "1  [Kauan, Alexandre, Mendes, da, Silva]   \n",
       "2            [João, Pedro, de, Oliveira]   \n",
       "3                  [Vinicius, Rebelatto]   \n",
       "4                [Lara, Cristina, Souza]   \n",
       "\n",
       "                                           descricao  \\\n",
       "0  [Sou, um, tatuador, especializado, em, Old, Sc...   \n",
       "1                          [Realismo, mágico, |, SP]   \n",
       "2  [O, tatuador, mais, fofo, de, fineline, de, Po...   \n",
       "3           [Leões, e, relógios, ,, praia, e, vôlei]   \n",
       "4  [Tatuagens, delicadas, e, florais, com, alma, ...   \n",
       "\n",
       "                                          hashtags  \n",
       "0  [oldschool, curitiba, brasil, sao-paulo, retro]  \n",
       "1                  [realismo, sao-paulo, sp, rutz]  \n",
       "2                 [fineline, fofura, porto-alegre]  \n",
       "3          [leão, relógio, praia, volei, curitiba]  \n",
       "4      [delicada, floral, sp, sao-paulo, feminina]  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "\n",
    "pd.DataFrame({\n",
    "    'nome_completo': [word_tokenize(nome) for nome in df['nome_completo']],\n",
    "    'descricao': [word_tokenize(descricao) for descricao in df['descricao']],\n",
    "    'hashtags': [hashtag.split(',') for hashtag in df['hashtags']],\n",
    "}).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37d56630",
   "metadata": {},
   "source": [
    "### Gostei do resultado, mas precisamos sanitizar o nosso texto para garantir que as buscas são efetivas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a272a254",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sou', 'um', 'tatuador', 'especializado', 'em', 'old', 'school']\n",
      "['realismo', 'mágico', 'sp']\n",
      "['o', 'tatuador', 'mais', 'fofo', 'de', 'fineline', 'de', 'porto', 'alegre']\n",
      "['leões', 'e', 'relógios', 'praia', 'e', 'vôlei']\n",
      "['tatuagens', 'delicadas', 'e', 'florais', 'com', 'alma', 'feminina']\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def clean_text(text):\n",
    "    text = text.strip()\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = text.lower()\n",
    "    return text\n",
    "\n",
    "for descricao in df['descricao'].head():\n",
    "    print(word_tokenize(clean_text(descricao)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25715eaa",
   "metadata": {},
   "source": [
    "### Bora tirar também as _stop-words_ (\"e\", \"em\", etc).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "185a383c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tatuador', 'especializado', 'old', 'school']\n",
      "['realismo', 'mágico', 'sp']\n",
      "['tatuador', 'fofo', 'fineline', 'porto', 'alegre']\n",
      "['leões', 'relógios', 'praia', 'vôlei']\n",
      "['tatuagens', 'delicadas', 'florais', 'alma', 'feminina']\n",
      "['preto', 'cinza', 'sombra', 'pesada']\n",
      "['crânios', 'serpentes', 'tudo', 'sombrio']\n",
      "['mini', 'pokes', 'autorais', 'direto', 'bh']\n",
      "['arte', 'fina', 'traço', 'limpo', 'coração', 'cheio']\n",
      "['tradicional', 'americano', 'toque', 'brasileiro']\n",
      "['tatuagens', 'orientais', 'traço', 'preciso']\n",
      "['tribal', 'neotradicional', 'tudo', 'rio']\n",
      "['pontilhismo', 'mandalas', 'propósito']\n",
      "['neotradicional', 'cores', 'vivas', 'muita', 'energia']\n",
      "['especialista', 'blackwork', 'geométrico']\n",
      "['dotwork', 'intenso', 'simbologia', 'oculta']\n",
      "['aquarela', 'viva', 'pele', 'pura', 'emoção']\n",
      "['tribais', 'modernos', 'culturais']\n",
      "['fineline', 'referências', 'botânicas']\n",
      "['realismo', 'preto', 'cinza', 'emoção', 'real']\n",
      "['pontilhismo', 'espiritual', 'mandalas', 'únicas']\n",
      "['sketch', 'tattoo', 'alma', 'artista']\n",
      "['colorido', 'vibrante', 'traço', 'ousado']\n",
      "['old', 'school', 'raiz', 'traços', 'marcantes']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/thundera/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "nltk.download('stopwords')\n",
    "STOP_WORDS = set(stopwords.words('portuguese'))\n",
    "\n",
    "for descricao in df['descricao']:\n",
    "    palavras = word_tokenize(clean_text(descricao))\n",
    "    palavras_filtradas = [word for word in palavras if word not in STOP_WORDS]\n",
    "    print(palavras_filtradas)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66205013",
   "metadata": {},
   "source": [
    "### Por fim, bora resolver mais uma questão. _Stemming_."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6d3acd10",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['sou', 'um', 'tatuador', 'especializ', 'em', 'old', 'school']\n",
      "['realism', 'mágic', 'sp']\n",
      "['o', 'tatuador', 'mais', 'fof', 'de', 'finelin', 'de', 'port', 'alegr']\n",
      "['leõ', 'e', 'relógi', 'pra', 'e', 'vôl']\n",
      "['tatuagens', 'delic', 'e', 'flor', 'com', 'alma', 'feminin']\n",
      "['pret', 'e', 'cinz', 'com', 'sombr', 'pes']\n",
      "['crâni', 'serpent', 'e', 'tud', 'que', 'é', 'sombri']\n",
      "['min', 'pok', 'autor', 'diret', 'de', 'bh']\n",
      "['arte', 'fin', 'trac', 'limp', 'coraçã', 'chei']\n",
      "['tradicional', 'american', 'com', 'um', 'toqu', 'brasileir']\n",
      "['tatuagens', 'orient', 'com', 'trac', 'precis']\n",
      "['do', 'tribal', 'ao', 'neotradicional', 'tud', 'no', 'rio']\n",
      "['pontilh', 'e', 'mandal', 'com', 'propósit']\n",
      "['neotradicional', 'com', 'cor', 'viv', 'e', 'muit', 'energ']\n",
      "['especial', 'em', 'blackwork', 'geométr']\n",
      "['dotwork', 'intens', 'com', 'simbolog', 'ocult']\n",
      "['aquarel', 'viv', 'na', 'pel', 'pur', 'emoçã']\n",
      "['trib', 'modern', 'e', 'cultur']\n",
      "['finelin', 'com', 'referent', 'botân']\n",
      "['realism', 'pret', 'e', 'cinz', 'com', 'emoçã', 'real']\n",
      "['pontilh', 'espiritual', 'e', 'mandal', 'únic']\n",
      "['sketch', 'tatto', 'com', 'alma', 'de', 'artist']\n",
      "['color', 'vibrant', 'e', 'trac', 'ous']\n",
      "['old', 'school', 'raiz', 'com', 'trac', 'marcant']\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"portuguese\")\n",
    "\n",
    "for descricao in df['descricao']:\n",
    "    palavras = word_tokenize(clean_text(descricao))\n",
    "    tokens_stemmed = [stemmer.stem(word) for word in palavras]\n",
    "    print(tokens_stemmed)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd4720ed",
   "metadata": {},
   "source": [
    "### Beleza, tudo parece bom. Bora criar uma pipeline para os dados!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "62528a24",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt_tab to\n",
      "[nltk_data]     /home/thundera/nltk_data...\n",
      "[nltk_data]   Package punkt_tab is already up-to-date!\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /home/thundera/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome_completo</th>\n",
       "      <th>descricao</th>\n",
       "      <th>hashtags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[cai, henriqu, porcel]</td>\n",
       "      <td>[tatuador, especializ, old, school]</td>\n",
       "      <td>[oldschool, curitiba, brasil, sao-paulo, retro]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[kauan, alexandr, mend, silv]</td>\n",
       "      <td>[realism, mágic, sp]</td>\n",
       "      <td>[realismo, sao-paulo, sp, rutz]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[joã, pedr, oliveir]</td>\n",
       "      <td>[tatuador, fof, finelin, port, alegr]</td>\n",
       "      <td>[fineline, fofura, porto-alegre]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[vinicius, rebelatt]</td>\n",
       "      <td>[leõ, relógi, pra, vôl]</td>\n",
       "      <td>[leão, relógio, praia, volei, curitiba]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[lar, cristin, souz]</td>\n",
       "      <td>[tatuagens, delic, flor, alma, feminin]</td>\n",
       "      <td>[delicada, floral, sp, sao-paulo, feminina]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>[hug, martins]</td>\n",
       "      <td>[pret, cinz, sombr, pes]</td>\n",
       "      <td>[blackandgrey, sombra, power, rio, rj]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>[daniel, roch]</td>\n",
       "      <td>[crâni, serpent, tud, sombri]</td>\n",
       "      <td>[dark, skull, serpente, gótica, sao-paulo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>[fern, lim]</td>\n",
       "      <td>[min, pok, autor, diret, bh]</td>\n",
       "      <td>[minipoke, bh, autoral, tattoo, minimalista]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>[marian, cost]</td>\n",
       "      <td>[arte, fin, trac, limp, coraçã, chei]</td>\n",
       "      <td>[fineline, fineart, amor, sp, minimal]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>[eduard, pereir]</td>\n",
       "      <td>[tradicional, american, toqu, brasileir]</td>\n",
       "      <td>[tradicional, oldschool, brasil, curitiba, tat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>[beatriz, tanak]</td>\n",
       "      <td>[tatuagens, orient, trac, precis]</td>\n",
       "      <td>[japonesa, oriental, precisão, sao-paulo, arte]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>[cai, mend]</td>\n",
       "      <td>[tribal, neotradicional, tud, rio]</td>\n",
       "      <td>[tribal, neotradicional, riodejaneiro, rj, bra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>[alin, barret]</td>\n",
       "      <td>[pontilh, mandal, propósit]</td>\n",
       "      <td>[pontilhismo, mandala, espiritual, sp, sagrado]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>[gustav, andrad]</td>\n",
       "      <td>[neotradicional, cor, viv, muit, energ]</td>\n",
       "      <td>[neotradicional, cores, vibrante, porto-alegre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>[julian, ferreir]</td>\n",
       "      <td>[especial, blackwork, geométr]</td>\n",
       "      <td>[blackwork, geométrico, sp, minimal, arte]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>[leonard, mat]</td>\n",
       "      <td>[dotwork, intens, simbolog, ocult]</td>\n",
       "      <td>[dotwork, simbólico, tatuagem, sp, místico]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>[carolin, dias]</td>\n",
       "      <td>[aquarel, viv, pel, pur, emoçã]</td>\n",
       "      <td>[aquarela, colorido, emoção, rio, rj]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>[rafael, albuquerqu]</td>\n",
       "      <td>[trib, modern, cultur]</td>\n",
       "      <td>[tribal, cultura, ancestral, brasilia, arte]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>[isador, menez]</td>\n",
       "      <td>[finelin, referent, botân]</td>\n",
       "      <td>[fineline, botânico, natural, curitiba, minima...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>[thiag, cost]</td>\n",
       "      <td>[realism, pret, cinz, emoçã, real]</td>\n",
       "      <td>[realismo, blackandgrey, detalhado, sp, sao-pa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>[lucian, andrad]</td>\n",
       "      <td>[pontilh, espiritual, mandal, únic]</td>\n",
       "      <td>[mandala, pontilhismo, espiritualidade, rj, arte]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>[eduard, roch]</td>\n",
       "      <td>[sketch, tatto, alma, artist]</td>\n",
       "      <td>[sketch, autoral, arte, bh, criatividade]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>[nathal, gom]</td>\n",
       "      <td>[color, vibrant, trac, ous]</td>\n",
       "      <td>[colorido, vibrante, sp, sao-paulo, tattoo]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>[brun, figueir]</td>\n",
       "      <td>[old, school, raiz, trac, marcant]</td>\n",
       "      <td>[oldschool, tradicional, tattoo, retro, brasil]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    nome_completo                                 descricao  \\\n",
       "0          [cai, henriqu, porcel]       [tatuador, especializ, old, school]   \n",
       "1   [kauan, alexandr, mend, silv]                      [realism, mágic, sp]   \n",
       "2            [joã, pedr, oliveir]     [tatuador, fof, finelin, port, alegr]   \n",
       "3            [vinicius, rebelatt]                   [leõ, relógi, pra, vôl]   \n",
       "4            [lar, cristin, souz]   [tatuagens, delic, flor, alma, feminin]   \n",
       "5                  [hug, martins]                  [pret, cinz, sombr, pes]   \n",
       "6                  [daniel, roch]             [crâni, serpent, tud, sombri]   \n",
       "7                     [fern, lim]              [min, pok, autor, diret, bh]   \n",
       "8                  [marian, cost]     [arte, fin, trac, limp, coraçã, chei]   \n",
       "9                [eduard, pereir]  [tradicional, american, toqu, brasileir]   \n",
       "10               [beatriz, tanak]         [tatuagens, orient, trac, precis]   \n",
       "11                    [cai, mend]        [tribal, neotradicional, tud, rio]   \n",
       "12                 [alin, barret]               [pontilh, mandal, propósit]   \n",
       "13               [gustav, andrad]   [neotradicional, cor, viv, muit, energ]   \n",
       "14              [julian, ferreir]            [especial, blackwork, geométr]   \n",
       "15                 [leonard, mat]        [dotwork, intens, simbolog, ocult]   \n",
       "16                [carolin, dias]           [aquarel, viv, pel, pur, emoçã]   \n",
       "17           [rafael, albuquerqu]                    [trib, modern, cultur]   \n",
       "18                [isador, menez]                [finelin, referent, botân]   \n",
       "19                  [thiag, cost]        [realism, pret, cinz, emoçã, real]   \n",
       "20               [lucian, andrad]       [pontilh, espiritual, mandal, únic]   \n",
       "21                 [eduard, roch]             [sketch, tatto, alma, artist]   \n",
       "22                  [nathal, gom]               [color, vibrant, trac, ous]   \n",
       "23                [brun, figueir]        [old, school, raiz, trac, marcant]   \n",
       "\n",
       "                                             hashtags  \n",
       "0     [oldschool, curitiba, brasil, sao-paulo, retro]  \n",
       "1                     [realismo, sao-paulo, sp, rutz]  \n",
       "2                    [fineline, fofura, porto-alegre]  \n",
       "3             [leão, relógio, praia, volei, curitiba]  \n",
       "4         [delicada, floral, sp, sao-paulo, feminina]  \n",
       "5              [blackandgrey, sombra, power, rio, rj]  \n",
       "6          [dark, skull, serpente, gótica, sao-paulo]  \n",
       "7        [minipoke, bh, autoral, tattoo, minimalista]  \n",
       "8              [fineline, fineart, amor, sp, minimal]  \n",
       "9   [tradicional, oldschool, brasil, curitiba, tat...  \n",
       "10    [japonesa, oriental, precisão, sao-paulo, arte]  \n",
       "11  [tribal, neotradicional, riodejaneiro, rj, bra...  \n",
       "12    [pontilhismo, mandala, espiritual, sp, sagrado]  \n",
       "13  [neotradicional, cores, vibrante, porto-alegre...  \n",
       "14         [blackwork, geométrico, sp, minimal, arte]  \n",
       "15        [dotwork, simbólico, tatuagem, sp, místico]  \n",
       "16              [aquarela, colorido, emoção, rio, rj]  \n",
       "17       [tribal, cultura, ancestral, brasilia, arte]  \n",
       "18  [fineline, botânico, natural, curitiba, minima...  \n",
       "19  [realismo, blackandgrey, detalhado, sp, sao-pa...  \n",
       "20  [mandala, pontilhismo, espiritualidade, rj, arte]  \n",
       "21          [sketch, autoral, arte, bh, criatividade]  \n",
       "22        [colorido, vibrante, sp, sao-paulo, tattoo]  \n",
       "23    [oldschool, tradicional, tattoo, retro, brasil]  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import SnowballStemmer\n",
    "\n",
    "nltk.download('punkt_tab')\n",
    "nltk.download('stopwords')\n",
    "\n",
    "STOP_WORDS = set(stopwords.words('portuguese'))\n",
    "STEMMER = SnowballStemmer(\"portuguese\")\n",
    "\n",
    "def sanitizar_texto(texto: str) -> str:\n",
    "    texto = texto.strip()\n",
    "    texto = re.sub(r'[^\\w\\s]', '', texto)\n",
    "    texto = texto.lower()\n",
    "    \n",
    "    return texto\n",
    "\n",
    "def tokenizar_texto(texto: str) -> list[str]:\n",
    "    return word_tokenize(texto)\n",
    "\n",
    "def remover_stopwords(tokens: list[str]) -> list[str]:\n",
    "    return [word for word in tokens if word not in STOP_WORDS]\n",
    "\n",
    "def aplicar_stemming(tokens: list[str]) -> list[str]:\n",
    "    return [STEMMER.stem(word) for word in tokens]\n",
    "\n",
    "def pipeline(texto: str) -> list[str]:\n",
    "    texto_sanitizado = sanitizar_texto(texto)\n",
    "    texto_tokenizado = tokenizar_texto(texto_sanitizado)\n",
    "    tokens_relevantes = remover_stopwords(texto_tokenizado)\n",
    "    \n",
    "    return tokens_relevantes\n",
    "\n",
    "df_tokens = pd.DataFrame({\n",
    "    'nome_completo': [aplicar_stemming(pipeline(nome)) for nome in df['nome_completo']],\n",
    "    'descricao': [aplicar_stemming(pipeline(descricao)) for descricao in df['descricao']],\n",
    "    'hashtags': [hashtag.split(',') for hashtag in df['hashtags']],\n",
    "})\n",
    "\n",
    "df_tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1f9f287",
   "metadata": {},
   "source": [
    "### Agora, bora criar o índice invertido!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2df136a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Term</th>\n",
       "      <th>Documents</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cai</td>\n",
       "      <td>[0, 11]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>henriqu</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>porcel</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tatuador</td>\n",
       "      <td>[0, 2]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>especializ</td>\n",
       "      <td>[0]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>ous</td>\n",
       "      <td>[22]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>brun</td>\n",
       "      <td>[23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>figueir</td>\n",
       "      <td>[23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>raiz</td>\n",
       "      <td>[23]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>marcant</td>\n",
       "      <td>[23]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>185 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Term Documents\n",
       "0           cai   [0, 11]\n",
       "1       henriqu       [0]\n",
       "2        porcel       [0]\n",
       "3      tatuador    [0, 2]\n",
       "4    especializ       [0]\n",
       "..          ...       ...\n",
       "180         ous      [22]\n",
       "181        brun      [23]\n",
       "182     figueir      [23]\n",
       "183        raiz      [23]\n",
       "184     marcant      [23]\n",
       "\n",
       "[185 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "inverted_index = defaultdict(set)\n",
    "\n",
    "for idx, row in df_tokens.iterrows():\n",
    "    tokens = row['nome_completo'] + row['descricao']\n",
    "    \n",
    "    for token in tokens:\n",
    "        inverted_index[token].add(idx)\n",
    "\n",
    "df_index = pd.DataFrame([(term, list(doc_ids)) for term, doc_ids in inverted_index.items()], columns=[\"Term\", \"Documents\"])\n",
    "df_index.to_csv('out.csv')\n",
    "\n",
    "df_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.12.3)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
